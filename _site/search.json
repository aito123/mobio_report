[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mobio reports",
    "section": "",
    "text": "Repository of Mobio Reports.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\n\n\n\n\n\n\n\nMar 5, 2023\n\n\nCAMH sid issue\n\n\n\n\n\n\n\nFeb 21, 2023\n\n\nDate’s problem\n\n\n\n\n\n\n\nFeb 21, 2023\n\n\nReported stress problem\n\n\n\n\n\n\n\nJan 24, 2023\n\n\nDuplicate’s problem\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/camh_problem.html#problem",
    "href": "posts/camh_problem.html#problem",
    "title": "CAMH sid issue",
    "section": "Problem",
    "text": "Problem\n\nIn communication with Alexander Daros from CAMH Institute, it is informed that there is a problem with sid code of some users that are been defaulted to null"
  },
  {
    "objectID": "posts/camh_problem.html#objectives",
    "href": "posts/camh_problem.html#objectives",
    "title": "CAMH sid issue",
    "section": "Objectives",
    "text": "Objectives\n\nIdentify the CAMH observation with sid defaulted to null and other problems in sid variable.\n\nFor the purpose of this report, we are going to use the data from BecharaReport API gathered in 2023-03-04. This data has 1’780’739 observations and 80 variables, and can be found in the following Dropbox path:\nMobio Interactive Dropbox/Research/RWD/Shared R Scripts/Input csv/BecharaReportFull-2023-03-04T05_15_17.csv\nAfter applying the procedure to reduce the number of duplicates in the data, we have 71’897 observations in data.\nLet’s enumerate the issues with CAMH sid variable:"
  },
  {
    "objectID": "posts/camh_problem.html#obj-1-identifying-observations",
    "href": "posts/camh_problem.html#obj-1-identifying-observations",
    "title": "CAMH sid issue",
    "section": "Obj 1: Identifying observations",
    "text": "Obj 1: Identifying observations\nAfter applying the procedure to reduce the number of duplicates in the data, we have 71’897 observations in data.\nAlex already identified half of CAMH users with null sid and provided the following conversion:\n\n\n\ncoupon_code\ncurrent_sid\nnew_sid\n\n\n\n\nufbtyvp2\nnull\ncamh_7004\n\n\njgsnb6d8\nnull\ncamh_7007\n\n\np5xmktv8\nnull\ncamh_7025\n\n\nmengc4dt\nnull\ncamh_7034\n\n\na4ph6gp8\nnull\ncamh_7034\n\n\n3v4jcxnc\nnull\ncamh_7037\n\n\nydxbcyqu\nnull\ncamh_7026\n\n\nbxab7jeh\nnull\ncamh_7053\n\n\nzqr73whw\nnull\ncamh_7057\n\n\nyd5vnj95\nnull\ncamh_7068\n\n\nwg3wx7ak\nnull\ncamh_7073\n\n\n66gp5h94\nnull\ncamh_7078\n\n\nr65y6hp7\nnull\ncamh_7077\n\n\nxjeg249g\nnull\ncamh_7076\n\n\n45j4vt7v\nnull\ncamh_7086\n\n\nvt6xbrbr\nnull\ncamh_7096\n\n\nn8bvq4up\nnull\ncamh_7094\n\n\ns9j2wjnu\nnull\ncamh_7104\n\n\nv53hmcz8\nnull\ncamh_7104\n\n\nphhpyzv3\nnull\ncamh_7111\n\n\nzxkaa578\nnull\ncamh_7112\n\n\nb5tzbeh4\nnull\ncamh_7127\n\n\nmtn6kp3f\nnull\ncamh_7131\n\n\nxvgaactr\nnull\ncamh_7137\n\n\njupk62f4\nnull\ncamh_7141\n\n\n\nIs important to mention that there are not user_uuid with the same sid correction.\nThe remaining cases that are null are the following:\n\n\n\n\ncoupon_code\ncurrent_sid\nnew_sid\n\n\n\n\n6yp59wdk\ncamh_null\n\n\n\nxkevd9da\nnull\n\n\n\nf4smzshd\nnull\n\n\n\ns6dkng9d\nnull\n\n\n\n28qxp744\nnull\n\n\n\nkxtf4umn\nnull\n\n\n\nrzx6q8mt\nnull\n\n\n\n4njqzx2e\nnull\n\n\n\naeyfr9ec\nnull\n\n\n\naf3u42s6\nnull\n\n\n\ngdy5ur6n\nnull\n\n\n\nnbf9zuzc\nnull\n\n\n\nb3upeaft\nnull\n\n\n\neeue6jd4\nnull\n\n\n\nbfqp35wx\nnull\n\n\n\ndgsbjt8b\nnull\n\n\n\ncf42ydk5\nnull\n\n\n\nrdqhctrf\nnull\n\n\n\nnqzycgmj\nnull\n\n\n\nqj3j9sgd\nnull\n\n\n\nymhecrng\nnull\n\n\n\nn6mwhufq\nnull\n\n\n\n6pe4gw6z\nnull\n\n\n\nsmmeerwr\ncamh_null\n\n\n\nhkeg45y2\nnull\n\n\n\nfkduwsss\nnull\n\n\n\n6uk9kqca\ncamh_null\n\n\n\nno id\nnull\n\n\n\ns63yez77\nnull\n\n\n\n4d5qy3j6\nnull\n\n\n\nxqrr5tej\nnull"
  },
  {
    "objectID": "posts/dates_problem.html#problem",
    "href": "posts/dates_problem.html#problem",
    "title": "Date’s problem",
    "section": "Problem",
    "text": "Problem\n\nThe date-time variables appear in different formats in the data downloaded from BecharaReport API.\nSome values of date-time variables does not reflect the date-time of the user considering their timezone."
  },
  {
    "objectID": "posts/dates_problem.html#objectives",
    "href": "posts/dates_problem.html#objectives",
    "title": "Date’s problem",
    "section": "Objectives",
    "text": "Objectives\n\nDescribe the problem.\nExplain the origin of the problem.\n\nFor the purpose of this report, we are going to use the data from BecharaReport API gathered in 2023-01-25. This data has 799362 observations and 80 variables, and can be found in the following Dropbox path:\nMobio Interactive Dropbox/Research/RWD/Shared R Scripts/Input csv/BecharaReportFull-2023-01-25T17_00_16.csv."
  },
  {
    "objectID": "posts/dates_problem.html#obj-1-describing-the-problem",
    "href": "posts/dates_problem.html#obj-1-describing-the-problem",
    "title": "Date’s problem",
    "section": "Obj 1: Describing the problem",
    "text": "Obj 1: Describing the problem\nIn the AmDTx data downloaded from BecharaReport API we have the following 10 date-time variables:\n\nDefinitions from BecharaReport+\n\n\n\n\n\n\nOfficial label\nDefinition\n\n\n\n\ncreated\nTimestamp of account creation\n\n\nsession_start\nUnique timestamp of AmDTx session start\n\n\nsession_finish\nUnique timestamp of AmDTx session finish\n\n\nsnapshot_start_pre\nUnique timestamp of AmDTx snapshot start (pre session or standalone)\n\n\nsnapshot_finish_pre\nUnique timestamp of AmDTx snapshot finish (pre session or standalone)\n\n\nsnapshot_start_post\nUnique timestamp of AmDTx snapshot start (post session or standalone)\n\n\nsnapshot_finish_post\nUnique timestamp of AmDTx snapshot finish (post session or standalone)\n\n\nintent_start\nTimestamp of user initiating Intent portion of My Moment feature\n\n\nintent_finish\nTimestamp of user completing Intent portion of My Moment feature\n\n\nredeem_date\nWhen a coupon was applied to a user’s account\n\n\nbadges\nList of badges that the user has been awared up to the snapshot/session initiation\n\n\n\nThis variables appear in the database in the following way:\n\n\n\n Selection of time & datetime variables considering user ID and session ID\n  \n\n\n\n\nDate-time formats\nThere are different time formats for date-time information:\n\nDate-time formats from UTC Time Now\n\n\nDate-Time Format\nUTC Date Time Now\n\n\n\n\nUTC\n2023-01-25T13:47:24Z\n\n\nISO-8601\n2023-01-25T13:47:24+0000\n\n\nRFC 2822\nWed, 25 Jan 2023 13:47:24 +0000\n\n\nRFC 850\nWednesday, 25-Jan-23 13:47:24 UTC\n\n\nRFC 1036\nWed, 25 Jan 23 13:47:24 +0000\n\n\nRFC 1123\nWed, 25 Jan 2023 13:47:24 +0000\n\n\nRFC 822\nWed, 25 Jan 23 13:47:24 +0000\n\n\nRFC 3339\n2023-01-25T13:47:24+00:00\n\n\nATOM\n2023-01-25T13:47:24+00:00\n\n\nCOOKIE\nWednesday, 25-Jan-2023 13:47:24 UTC\n\n\nRSS\nWed, 25 Jan 2023 13:47:24 +0000\n\n\nW3C\n2023-01-25T13:47:24+00:00\n\n\nUnix Epoch\n1674654444\n\n\nYYYY-DD-MM HH:MM:SS\n2023-25-01 13:47:24\n\n\nYYYY-DD-MM HH:MM:SS am/pm\n2023-25-01 01:47:24 PM\n\n\nDD-MM-YYYY HH:MM:SS\n25-01-2023 13:47:24\n\n\nMM-DD-YYYY HH:MM:SS\n01-25-2023 13:47:24\n\n\n\nIn BecharaReport data we can see date-time variables formatted in UTC format and W3C format.\nIn W3C format, the +00:00 at the end of the string means how many hh:mm the time is offset from UTC (Universal Time Coordinated). To know how many hours offset a place is from UTC, we can follow this map time, although in practice there are some exceptions:\n\n\nUTC offset world map\n\n\n\nLet’s enumerate the following incongruencies in the date-time variables:\n\n\nFormat problem\n\nW3C format: created, session_start, session_finish, snapshot_start_pre, snapshot_finish_pre, snapshot_start_post, snapshot_finish_post, redeem_date, badge\n\n\n\n\n\n  \n\n\n\n\nUTC format: intent_start, intent_finish\n\nThis variables are already defaulted UTC +00:00.\n\n\n\n\n\n\n  \n\n\n\n\n\nAtypic values instead of NA\n\nIntent start & finish are variables present in “My Moment” sessions. In case of other types of sessions the backend is defaulting the missing value as 0001-01-01T00:00Z.\n\n\n\nNumber of distinct observations equal to 0001-01-01T00:00Z by different types in BecharaReport API data:\n\n\n\n\n\n\nintent_start \n  \n  \n    \n      type\n      intent_start\n      n\n      % in type\n    \n  \n  \n    <snapshot>\n0001-01-01T00:00Z\n1371\n6.17\n    ac2048\n0001-01-01T00:00Z\n137\n100.00\n    JourneyActivity\n0001-01-01T00:00Z\n229\n51.12\n    JourneyLesson\n0001-01-01T00:00Z\n20482\n86.74\n    JourneyTimer\n0001-01-01T00:00Z\n433\n86.43\n    Library\n0001-01-01T00:00Z\n7880\n80.38\n    None\n0001-01-01T00:00Z\n4\n66.67\n    Timer\n0001-01-01T00:00Z\n3846\n80.88\n  \n  \n  \n\n\n\n\n\n\n\nintent_finish \n  \n  \n    \n      type\n      intent_finish\n      n\n      % in type\n    \n  \n  \n    <snapshot>\n0001-01-01T00:00Z\n1371\n6.17\n    ac2048\n0001-01-01T00:00Z\n137\n100.00\n    JourneyActivity\n0001-01-01T00:00Z\n229\n51.12\n    JourneyLesson\n0001-01-01T00:00Z\n20482\n86.74\n    JourneyTimer\n0001-01-01T00:00Z\n433\n86.43\n    Library\n0001-01-01T00:00Z\n7880\n80.38\n    None\n0001-01-01T00:00Z\n4\n66.67\n    Timer\n0001-01-01T00:00Z\n3846\n80.88\n  \n  \n  \n\n\n\n\n\n\n\nTime-zone problem\n\nThe date-time variables define the UTC offset +00:00 according to the location of the user. When some date-time variables are not able to retrieve the GPS location of the user, then it defaults UTC to +00:00.\nThis is a problem because if we are interested in the local time of the user (e.g if the user used the AmDTx app in the morning or at night) then defaulting to +00:00 would change that local time.\nFor example, if the user is in Lima, Peru (UTC -05:00 ) and uses the app at 8:49pm, it would be defaulted to 1:49am.\n\nDate-time conversion\n\n\n\n\n\n\nPeru time (EST) / UTC -05:00\nUTC +00:00\n\n\n\n\n2023-01-10T20:49:33-05:00\n2023-01-11 01:49:33 UTC\n\n\n\n\nAll W3C format date-time variables are defaulted to UTC +00:00 with the exception of badge variable.\n\n\n\n\n\n\n\n  \n  \n    \n      created\n      n\n    \n  \n  \n    +00:00\n92386\n  \n  \n  \n\n\n\n\n\n\n\n\n  \n  \n    \n      session_start\n      n\n    \n  \n  \n    +00:00\n46097\n    NA\n46289\n  \n  \n  \n\n\n\n\n\n\n\n\n  \n  \n    \n      session_finish\n      n\n    \n  \n  \n    +00:00\n46097\n    NA\n46289\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n  \n  \n    \n      snapshot_start_pre\n      n\n    \n  \n  \n    +00:00\n43971\n    NA\n48415\n  \n  \n  \n\n\n\n\n\n\n\n\n  \n  \n    \n      snapshot_finish_pre\n      n\n    \n  \n  \n    +00:00\n43971\n    NA\n48415\n  \n  \n  \n\n\n\n\n\n\n\n\n  \n  \n    \n      snapshot_start_post\n      n\n    \n  \n  \n    +00:00\n19242\n    NA\n73144\n  \n  \n  \n\n\n\n\n\n\n\n\n\n\n  \n  \n    \n      snapshot_finish_post\n      n\n    \n  \n  \n    +00:00\n19242\n    NA\n73144\n  \n  \n  \n\n\n\n\n\n\n\n\n  \n  \n    \n      redeem_date\n      n\n    \n  \n  \n    +00:00\n44184\n    NA\n48202\n  \n  \n  \n\n\n\n\nNumber of distinct observations defaulted to UTC +00:00:\n\n\n\n\n\nBadge situation\nAs its definition says, badge represents a list of badges the user gains by using the app. This variable records the user badges in the following format:\n\n{badge1,badge2,badge3}\nFor example: {B001:2019-07-18T12:15:40-07:00,B004:2019-07-25T07:00:54-07:00,B003:2019-06-18T12:15:40-07:00}\nNot necessarily in order.\n\n\n\n\n Displaying distinct observations in badge variable\n  \n\n\n\nAs we can see, badge variable is recording the UTC offset of the badge gain and this can provide a future solution for the date-time problem if we apply the same principle of date-time recording to the other date-time variables."
  },
  {
    "objectID": "posts/dates_problem.html#obj-2-origin-of-the-problem",
    "href": "posts/dates_problem.html#obj-2-origin-of-the-problem",
    "title": "Date’s problem",
    "section": "Obj 2: Origin of the problem",
    "text": "Obj 2: Origin of the problem\nAs in the duplicate’s problem, part of the problem could be in the extraction of the data by BecharaReport API. Although, for example the atypic values problem also appear in the SQLPad database.\nFurther explanation about the problem could be found in the way SQL’s timestamp & timestampz are being used to store the date-time in AmDTx database. More documentation about this variables could be found in Cockroach Labs, MySQL\n\nInformation from SQL Pad\n\n\nOfficial label\nVariable type in database\n\n\n\n\ncreated\ntimestampz\n\n\nsession_start\ntimestampz\n\n\nsession_finish\ntimestampz\n\n\nsnapshot_start_pre\ntimestamp\n\n\nsnapshot_finish_pre\ntimestamp\n\n\nsnapshot_start_post\ntimestamp\n\n\nsnapshot_finish_post\ntimestamp\n\n\nintent_start\ntimestamp\n\n\nintent_finish\ntimestamp\n\n\nredeem_date\ntimestamp\n\n\nbadges\nvarchar\n\n\n\nThere is a variable called last_access_utc in user_token table which does not appear in BecharaReport+, further gathering in this variable is recommended."
  },
  {
    "objectID": "posts/duplicate_problem.html#problem",
    "href": "posts/duplicate_problem.html#problem",
    "title": "Duplicate’s problem",
    "section": "Problem",
    "text": "Problem\n\nThere are duplicates in the CSV data exported from BecharaReport API."
  },
  {
    "objectID": "posts/duplicate_problem.html#objectives",
    "href": "posts/duplicate_problem.html#objectives",
    "title": "Duplicate’s problem",
    "section": "Objectives",
    "text": "Objectives\n\nDescribe the problem.\nExplain the origin of the problem.\n\nFor the purpose of this report, we are going to use the data from BecharaReport API gathered in 2022-12-24. This data has 552393 observations and 80 variables, and can be found in the following Dropbox path:\nMobio Interactive Dropbox/Research/RWD/Shared R Scripts/Input csv/BecharaReportFull-2022-12-24T06_01_37.csv."
  },
  {
    "objectID": "posts/duplicate_problem.html#obj-1-describing-the-problem",
    "href": "posts/duplicate_problem.html#obj-1-describing-the-problem",
    "title": "Duplicate’s problem",
    "section": "Obj 1: Describing the problem",
    "text": "Obj 1: Describing the problem\nThe current approach to know how many AmDTx unique accounts created in the data is using the following code:\n\n\n\n\n  \n  Unique users with account creation type\n  \n  \n    \n      n\n    \n  \n  \n    732\n  \n  \n  \n\n\n\n\nAt 2022-12-24, we have 732 AmDTx unique accounts created using “account_creation” type. This type of observation is not present in every user, that is why there could be more users present in data.\nThis doesn’t solve duplicates problem, we are just telling R to count the distinct observations in the variable user_uuid filtering only the “account_creation” type.\nIf we want the make calculations about the user metrics, we need the unique observations in the data. For the purpose of this report we are going to select a random user and analyze its duplicates rows:\nUser: 19092f19-792f-42bc-b229-2444b52be4df\n\n\n\nThis user has 449 observations in data. At a glance we can see that this user actually has 16 unique observations. We can use the function distinct() to drop all the duplicates of an observation and only maintain the original one.\n\n\n\n All observation of sample user\n  \n\n\n\n\n\n\nIn this case, now we have 46 observations, which is less but is not 16 observations that is what we want.\nLet’s focus our attention in the session_uuid of the 46 observations. We can see that session_uuid = 292d1290-51a2-4cf2-89e3-7d26628a19a5 repeats 3 times.\n\n\n\n All duplicates of a same observation of sample user\n  \n\n\n\nWe can see that even if this are the same session_uuid, the same observation, there are incongruencies with the following variables:\n\nUpper-lower case problem:\n\nstandalone : has values formatted true/false and also TRUE/FALSE.\n\n\n\n\n\n Upper-lower case problem\n  \n\n\n\n\nRounding problem:\n\no2level_pre, hrv_low_freq_sum_pre, hrv_high_freq_sum_pre, hrv_low_freq_sum_post, hrv_high_freq_sum_post : the same observation could be rounded to the 6 decimal or sometimes more. Is probable that all numeric variables could have this problem.\nreported_stress_pre, reported_stress_post, mood_quality_pre, mood_quality_post : the same observation sometimes has one decimal.\n\n\n\n\n\n Rounding problem\n  \n\n\n\n\nComputing problem:\n\ncomputed_stress_pre, computed_stress_post : this variable has a major issue, because in some cases it reflects the accurate value (e.g 0.4224225) and in other cases its -1 (which is the default when de API finds missing values in this variable). This inconsistency could be a problem in the storage of the data when calling the API.\n\n\n\n\n\n Computing problem\n  \n\n\n\n\nUpdate problem:\n\nbadge : this is a different type of problem. Badge variable collects the information about the badges the user is rewarded. This field keeps updating through the duplicate observation.\n\n\n\n\n\n Update problem\n  \n\n\n\nThe update problem gives us some insight about the general problem in the database. We can see that the problem with the database is not a duplicate problem is a record situation.\n\nDuplicates inside static data:\n\nThere wer duplicated observations inside static data, probably in Lost data from China (CN).\n\nDuplicates bewteen static data and dynamic data:\n\nProbably Lost data from China (CN) had observations already present in Am current data (BecharaReport API).\n\nDuplicated paths in Meditation table (MT)\n\nMT table is been joined with Am data by the audio path (.ogg file) to get more information about the meditation characteristics. Although there are duplicate paths in MT data (for example, a same audio log is repeated in different languages). This is generating duplicates when joined.\n\n\n\nRecord situation\nUnderstanding the database as a record data can help us to solve the majority of the problems in the database.\nA solution for the record situation involves the following indications:\n\nRather than keep one of the duplicates randomnly, we can keep the latest observation of the recorded data.\n\nTo know the latest observation in the data, we need a unique id for each observation.\nThis approach can solve the upper-lower case problem, rounding problem, and update problem.\n\nAlthough only applying the solution of the latest observation doesn’t solve the computing problem. It’s necessary to ensure that the preserved observation has the correct computed_stress_pre, computed_stress_post and not only -1 when is not the case."
  },
  {
    "objectID": "posts/duplicate_problem.html#obj-2-origin-of-the-problem",
    "href": "posts/duplicate_problem.html#obj-2-origin-of-the-problem",
    "title": "Duplicate’s problem",
    "section": "Obj 2: Origin of the problem",
    "text": "Obj 2: Origin of the problem\nA hypothesis of the origin of the problem, knowing that is a record situation,\nIn collaboration with Backend team, we determined the origin of the problem was in the API."
  },
  {
    "objectID": "posts/reported_stress_problem.html#problem",
    "href": "posts/reported_stress_problem.html#problem",
    "title": "Reported stress problem",
    "section": "Problem",
    "text": "Problem\n\nReported_stress variables are defaulting all observations to -1, left_blank, NA, etc."
  },
  {
    "objectID": "posts/reported_stress_problem.html#objectives",
    "href": "posts/reported_stress_problem.html#objectives",
    "title": "Reported stress problem",
    "section": "Objectives",
    "text": "Objectives\n\nDescribe the problem.\nExplain the origin of the problem.\n\nFor the purpose of this report, we are going to use the data from BecharaReport API gathered in 2023-02-11. This data has 1’256’346 observations and 80 variables, and can be found in the following Dropbox path:\nMobio Interactive Dropbox/Research/RWD/Shared R Scripts/Input csv/BecharaReportFull-2023-02-11T01_34_20.csv."
  },
  {
    "objectID": "posts/reported_stress_problem.html#obj-1-describing-the-problem",
    "href": "posts/reported_stress_problem.html#obj-1-describing-the-problem",
    "title": "Reported stress problem",
    "section": "Obj 1: Describing the problem",
    "text": "Obj 1: Describing the problem\nAfter applying the procedure to reduce the number of duplicates in the data, we have 71’138 observations in data.\n\nAbout Reported stress\nReported stress variables (reported_stress_pre & reported_stress_post) capture the information from the stress slider in the snapshot interface:\n\n\nStress slidebar can go from 0 to 1\n\n\n\nThis information is present in all types of observation with the exception of account_creation.\nWhen this field of the snapshot interface is left blank or there’s an error in capturing this information, the application fills this variable with default values as -1, -1.0, left_blank, NA.\nThis scenario should be the exception, but we will see in the data that is actually the norm.\n\n\n\n\n\nIn this plot we have filtered out the observation type that are account_creation, then we grouped the observations by month and divide the normal values between 0 and 1 from the missing default values: -1, -1.0, left_blank, NA.\nAs we can see in the plot, historically we had more missing default values than normal values which is data we can work with.\n\n\n\n\n\nAlthough, if we consider zero also as a possible value inserted when data is missing, we can see that since 2022 we have only recorded missing default values in the variable reported_stress_pre.\n\n\n\n\n\nAs in the previous case, reported_stress_post has historically been populated with missing default values.\n\n\n\n\n\nAnd if we considered zero as a possible default value then since 2022 we had only recorded default values in this two variables."
  },
  {
    "objectID": "posts/reported_stress_problem.html#obj-2-origin-of-the-problem",
    "href": "posts/reported_stress_problem.html#obj-2-origin-of-the-problem",
    "title": "Reported stress problem",
    "section": "Obj 2: Origin of the problem",
    "text": "Obj 2: Origin of the problem\nWhen checking the SQL Pad, we can see that the problem is also present in the database.\nFor example, if we query a tabular table to count the values of reported_stress_pre between 2022 and 2023 we could see the following using this SQL syntax in each server:\nselect reported_stress, COUNT(*)\nfrom snapshots\nwhere\n(start BETWEEN '2022-01-01'AND '2023-02-12')\nGROUP BY reported_stress\n\nAU_DB_PRODCA_DB_PRODEU_DB_PRODHK_DB_PRODSG_DB_PROD\n\n\n\n\n\nreported_stress\ncount\n\n\n\n\n-1\n536\n\n\n\n\n\n\n\n\nreported_stress\ncount\n\n\n\n\n0\n4\n\n\n-1\n4655\n\n\n\n\n\n\n\n\nreported_stress\ncount\n\n\n\n\n-1\n215\n\n\n\n\n\n\n\n\nreported_stress\ncount\n\n\n\n\n-1\n23\n\n\n1\n2\n\n\n\n\n\n\n\n\nreported_stress\ncount\n\n\n\n\n0\n274\n\n\n-1\n1122"
  },
  {
    "objectID": "posts/camh_problem.html#identifying-null-observations",
    "href": "posts/camh_problem.html#identifying-null-observations",
    "title": "CAMH sid issue",
    "section": "Identifying null observations",
    "text": "Identifying null observations\nAlex already identified half of CAMH users with null sid, using coupon_code variable, and provided the following conversion:\n\n\n\ncoupon_code\ncurrent_sid\nnew_sid\n\n\n\n\nufbtyvp2\nnull\ncamh_7004\n\n\njgsnb6d8\nnull\ncamh_7007\n\n\np5xmktv8\nnull\ncamh_7025\n\n\nmengc4dt\nnull\ncamh_7034\n\n\na4ph6gp8\nnull\ncamh_7034\n\n\n3v4jcxnc\nnull\ncamh_7037\n\n\nydxbcyqu\nnull\ncamh_7026\n\n\nbxab7jeh\nnull\ncamh_7053\n\n\nzqr73whw\nnull\ncamh_7057\n\n\nyd5vnj95\nnull\ncamh_7068\n\n\nwg3wx7ak\nnull\ncamh_7073\n\n\n66gp5h94\nnull\ncamh_7078\n\n\nr65y6hp7\nnull\ncamh_7077\n\n\nxjeg249g\nnull\ncamh_7076\n\n\n45j4vt7v\nnull\ncamh_7086\n\n\nvt6xbrbr\nnull\ncamh_7096\n\n\nn8bvq4up\nnull\ncamh_7094\n\n\ns9j2wjnu\nnull\ncamh_7104\n\n\nv53hmcz8\nnull\ncamh_7104\n\n\nphhpyzv3\nnull\ncamh_7111\n\n\nzxkaa578\nnull\ncamh_7112\n\n\nb5tzbeh4\nnull\ncamh_7127\n\n\nmtn6kp3f\nnull\ncamh_7131\n\n\nxvgaactr\nnull\ncamh_7137\n\n\njupk62f4\nnull\ncamh_7141\n\n\n\nThe remaining cases that are null are the following:\n\n\n\n\ncoupon_code\ncurrent_sid\nnew_sid\n\n\n\n\n6yp59wdk\ncamh_null\n\n\n\nxkevd9da\nnull\n\n\n\nf4smzshd\nnull\n\n\n\ns6dkng9d\nnull\n\n\n\n28qxp744\nnull\n\n\n\nkxtf4umn\nnull\n\n\n\nrzx6q8mt\nnull\n\n\n\n4njqzx2e\nnull\n\n\n\naeyfr9ec\nnull\n\n\n\naf3u42s6\nnull\n\n\n\ngdy5ur6n\nnull\n\n\n\nnbf9zuzc\nnull\n\n\n\nb3upeaft\nnull\n\n\n\neeue6jd4\nnull\n\n\n\nbfqp35wx\nnull\n\n\n\ndgsbjt8b\nnull\n\n\n\ncf42ydk5\nnull\n\n\n\nrdqhctrf\nnull\n\n\n\nnqzycgmj\nnull\n\n\n\nqj3j9sgd\nnull\n\n\n\nymhecrng\nnull\n\n\n\nn6mwhufq\nnull\n\n\n\n6pe4gw6z\nnull\n\n\n\nsmmeerwr\ncamh_null\n\n\n\nhkeg45y2\nnull\n\n\n\nfkduwsss\nnull\n\n\n\n6uk9kqca\ncamh_null\n\n\n\nno id\nnull\n\n\n\ns63yez77\nnull\n\n\n\n4d5qy3j6\nnull\n\n\n\nxqrr5tej\nnull"
  },
  {
    "objectID": "posts/camh_problem.html#fixing-camh-prefix-in-sid-observations",
    "href": "posts/camh_problem.html#fixing-camh-prefix-in-sid-observations",
    "title": "CAMH sid issue",
    "section": "Fixing CAMH prefix in sid observations",
    "text": "Fixing CAMH prefix in sid observations\nThere are some sid codes that does not have the “camh_” prefix. Here a table with the observations with a suggested new sid:\n\n\n\n\ncoupon_code\ncurrent_sid\nnew_sid\n\n\n\n\ngjth44kr\n7148\ncamh_7148\n\n\n4p8zkjmf\n7157\ncamh_7157\n\n\ntvymhgqz\n7146\ncamh_7146\n\n\ncjmsh3r9\n7003\ncamh_7003\n\n\ng6r4wqmr\n9999\ncamh_9999\n\n\ns8ssgf6t\n7162\ncamh_7162\n\n\n5ckf36y3\n7151\ncamh_7151\n\n\n5jn6evad\n7142\ncamh_7142\n\n\n56skcxn3\ntest1\ncamh_test1\n\n\ndg4fbn77\n7160\ncamh_7160\n\n\nd6yqdq5w\ntest1\ncamh_test1\n\n\nfg65z37c\n7155\ncamh_7155\n\n\nb7k7hnex\n7147\ncamh_7147\n\n\n74du9sm3\n7143\ncamh_7143\n\n\ntzz63fpn\n7002\ncamh_7002\n\n\n5af6gxk8\n3\ncamh_0003\n\n\nefym3a3a\n7152\ncamh_7152\n\n\nr5g8xjsa\n7001\ncamh_7001\n\n\nkgp9s879\n7154\ncamh_7154\n\n\n4uxagkg9\n7153\ncamh_7153\n\n\nzm7pau7e\n7158\ncamh_7158\n\n\n2c27t5s7\n7145\ncamh_7145"
  },
  {
    "objectID": "posts/camh_problem.html#sid-shared-by-different-users",
    "href": "posts/camh_problem.html#sid-shared-by-different-users",
    "title": "CAMH sid issue",
    "section": "sid shared by different users",
    "text": "sid shared by different users\nLastly, the are some CAMH users that share the same sid code, which are not null sid’s, or have different coupon codes. For instance:\n\n\n\n\ncoupon_code\nsid\nuser_uuid\n\n\n\n\na4ph6gp8\ncamh_7034\n339545c0-4f8d-4df2-90f8-7d8f37c18c56\n\n\nyj6p39wx\ncamh_7038\n33f81739-97b3-42a5-83b1-14d8121ad7ad\n\n\nqcqwxhgy\ncamh_7040\n3c6ff988-6550-4c31-8fa4-c811bc38c500\n\n\nNA\ncamh_7091\n4a8ecf6a-f4fd-4c61-ac06-301ca2d43c5f\n\n\nno id\ncamh_7091\n4a8ecf6a-f4fd-4c61-ac06-301ca2d43c5f\n\n\nq7wqrk7z\ncamh_uid\n575564fe-fc8a-494f-83ad-c6894e763c59\n\n\n56skcxn3\ntest1\n5a172a2d-e3cc-48d2-8927-980f3c592dbf\n\n\nhd3rwm29\ncamh_7056\n5a952d6a-e9db-4265-a12f-04815bc81995\n\n\nd6yqdq5w\ntest1\n70aface8-1270-4003-9627-3ea3d31a9736\n\n\ny6z7tz8p\ncamh_7056\n7e7e03a9-7a36-44fd-9719-79ad05104e51\n\n\ns9j2wjnu\ncamh_7104\n849fb9e1-6f08-4630-bdc2-1cf55dc88dc0\n\n\nuwkbkeqs\ncamh_7040\na5af5ce9-8052-4a56-9bf8-8fc531d799e2\n\n\nc68xadk2\ncamh_7091\na8368a7e-bf94-47ff-bdae-78c8d606f836\n\n\nv53hmcz8\ncamh_7104\nbb97727e-1255-45ce-a067-ed8dc388d99b\n\n\nNA\ncamh_99999\nc2917e19-5656-4670-94fa-e8dabbed7e01\n\n\nno id\ncamh_99999\nc2917e19-5656-4670-94fa-e8dabbed7e01\n\n\nh57kgnjw\ncamh_7091\nc6941b31-f00a-4ef0-86b9-de342fd99944\n\n\n5dr467xr\ncamh_7038\nc7746a55-024f-4781-8a87-c584bfc508a4\n\n\nmengc4dt\ncamh_7034\nc80a272a-92c9-4bb1-adf6-04bc67d1dd49\n\n\nNA\ncamh_7103\nd4c492cc-9afd-4777-996e-af26ec71a093\n\n\nno id\ncamh_7103\nd4c492cc-9afd-4777-996e-af26ec71a093\n\n\njun8hgae\ncamh_uid\nfb0cb4c2-27d6-4e00-8a9d-b846cad1ea99"
  }
]