[
  {
    "objectID": "dates_problem.html#problem",
    "href": "dates_problem.html#problem",
    "title": "Date’s problem",
    "section": "Problem",
    "text": "Problem\n\nThe date-time variables appear in different formats in the data downloaded from BecharaReport API.\nSome values of date-time variables does not reflect the date-time of the user considering their timezone."
  },
  {
    "objectID": "dates_problem.html#objectives",
    "href": "dates_problem.html#objectives",
    "title": "Date’s problem",
    "section": "Objectives",
    "text": "Objectives\n\nDescribe the problem.\nExplain the origin of the problem.\n\nFor the purpose of this report, we are going to use the data from BecharaReport API gathered in 2023-01-25. This data has 799362 observations and 80 variables, and can be found in the following Dropbox path:\nMobio Interactive Dropbox/Research/RWD/Shared R Scripts/Input csv/BecharaReportFull-2023-01-25T17_00_16.csv."
  },
  {
    "objectID": "dates_problem.html#obj-1-describing-the-problem",
    "href": "dates_problem.html#obj-1-describing-the-problem",
    "title": "Date’s problem",
    "section": "Obj 1: Describing the problem",
    "text": "Obj 1: Describing the problem\nIn the AmDTx data downloaded from BecharaReport API we have the following 10 date-time variables:\n\nDefinitions from BecharaReport+\n\n\n\n\n\n\nVariable\nDefinition\n\n\n\n\ncreated\nTimestamp of account creation\n\n\nsession_start\nUnique timestamp of AmDTx session start\n\n\nsession_finish\nUnique timestamp of AmDTx session finish\n\n\nsnapshot_start_pre\nUnique timestamp of AmDTx snapshot start (pre session or standalone)\n\n\nsnapshot_finish_pre\nUnique timestamp of AmDTx snapshot finish (pre session or standalone)\n\n\nsnapshot_start_post\nUnique timestamp of AmDTx snapshot start (post session or standalone)\n\n\nsnapshot_finish_post\nUnique timestamp of AmDTx snapshot finish (post session or standalone)\n\n\nintent_start\nTimestamp of user initiating Intent portion of My Moment feature\n\n\nintent_finish\nTimestamp of user completing Intent portion of My Moment feature\n\n\nredeem_date\nWhen a coupon was applied to a user’s account\n\n\nbadge\nList of badges that the user has been awared up to the snapshot/session initiation\n\n\n\nThis variables appear in the database in the following way:\n\n\n\n Selection of time & datetime variables considering user ID and session ID\n  \n\n\n\n\nDate-time formats\nThere are different time formats for date-time information:\n\nDate-time formats from UTC Time Now\n\n\nDate-Time Format\nUTC Date Time Now\n\n\n\n\nUTC\n2023-01-25T13:47:24Z\n\n\nISO-8601\n2023-01-25T13:47:24+0000\n\n\nRFC 2822\nWed, 25 Jan 2023 13:47:24 +0000\n\n\nRFC 850\nWednesday, 25-Jan-23 13:47:24 UTC\n\n\nRFC 1036\nWed, 25 Jan 23 13:47:24 +0000\n\n\nRFC 1123\nWed, 25 Jan 2023 13:47:24 +0000\n\n\nRFC 822\nWed, 25 Jan 23 13:47:24 +0000\n\n\nRFC 3339\n2023-01-25T13:47:24+00:00\n\n\nATOM\n2023-01-25T13:47:24+00:00\n\n\nCOOKIE\nWednesday, 25-Jan-2023 13:47:24 UTC\n\n\nRSS\nWed, 25 Jan 2023 13:47:24 +0000\n\n\nW3C\n2023-01-25T13:47:24+00:00\n\n\nUnix Epoch\n1674654444\n\n\nYYYY-DD-MM HH:MM:SS\n2023-25-01 13:47:24\n\n\nYYYY-DD-MM HH:MM:SS am/pm\n2023-25-01 01:47:24 PM\n\n\nDD-MM-YYYY HH:MM:SS\n25-01-2023 13:47:24\n\n\nMM-DD-YYYY HH:MM:SS\n01-25-2023 13:47:24\n\n\n\nIn BecharaReport data we can see date-time variables formatted in UTC format and W3C format.\nIn W3C format, the +00:00 at the end of the string means how many hh:mm the time is offset from UTC (Universal Time Coordinated). To know how many hours offset a place is from UTC, we can follow this map time, although in practice there are some exceptions:\n\n\nUTC offset world map\n\n\n\nLet’s enumerate the following incongruencies in the date-time variables:\n\n\nFormat problem\n\nW3C format: created, session_start, session_finish, snapshot_start_pre, snapshot_finish_pre, snapshot_start_post, snapshot_finish_post, redeem_date, badge\n\n\n\n\n\n  \n\n\n\n\nUTC format: intent_start, intent_finish\n\nThis variables are already defaulted UTC +00:00.\n\n\n\n\n\n\n  \n\n\n\n\n\nAtypic values problem\n\nSome values have atypic date-time values that doesn’t make sense:\n\nintent_start, intent_finish: 0001-01-01T00:00Z\n\n\n\n\n\n\n  \n  Number of distinct observations with intent_start equal to 0001-01-01T00:00Z\n  \n  \n    \n      intent_start\n      n\n      %\n    \n  \n  \n    Other\n32163\n48.77\n    0001-01-01T00:00Z\n33785\n51.23\n  \n  \n  \n\n\n\n\n\n\n\n\n  \n  Number of distinct observations with intent_finish equal to 0001-01-01T00:00Z\n  \n  \n    \n      intent_finish\n      n\n      %\n    \n  \n  \n    Other\n32163\n48.77\n    0001-01-01T00:00Z\n33785\n51.23\n  \n  \n  \n\n\n\n\n\n\nTime-zone problem\n\nThe date-time variables define the UTC offset +00:00 according to the location of the user. When some date-time variables are not able to retrieve the GPS location of the user, then it defaults UTC to +00:00.\nThis is a problem because if we are interested in the local time of the user (e.g if the user used the AmDTx app in the morning or at night) then defaulting to +00:00 would change that local time.\nFor example, if the user is in Lima, Peru (UTC -05:00 ) and uses the app at 8:49pm, it would be defaulted to 1:49am.\n\nDate-time conversion\n\n\n\n\n\n\nPeru time (EST) / UTC -05:00\nUTC +00:00\n\n\n\n\n2023-01-10T20:49:33-05:00\n2023-01-11 01:49:33 UTC\n\n\n\nDefaulting to UTC +00:00 occurs in the followng variables:\n\n\n\n\n\n  \n  \n  \n  \n    \n      created\n      n\n    \n  \n  \n    +00:00\n4873\n  \n  \n  \n\n\n\n\n\n\n  \n  \n  \n  \n    \n      session_start\n      n\n    \n  \n  \n    \n1\n    +00:00\n29344\n  \n  \n  \n\n\n\n\n\n\n  \n  \n  \n  \n    \n      session_finish\n      n\n    \n  \n  \n    \n1\n    +00:00\n29343\n  \n  \n  \n\n\n\n\n\n\n  \n  \n  \n  \n    \n      snapshot_start_pre\n      n\n    \n  \n  \n    \n1\n    +00:00\n29399\n  \n  \n  \n\n\n\n\n\n\n  \n  \n  \n  \n    \n      snapshot_start_post\n      n\n    \n  \n  \n    \n1\n    +00:00\n12017\n  \n  \n  \n\n\n\n\n\n\n  \n  \n  \n  \n    \n      snapshot_finish_post\n      n\n    \n  \n  \n    \n1\n    +00:00\n12017\n  \n  \n  \n\n\n\n\n\n\n  \n  \n  \n  \n    \n      redeem_date\n      n\n    \n  \n  \n    \n1\n    +00:00\n1322\n  \n  \n  \n\n\n\n\n\n\n  \n  \n  \n  \n    \n      redeem_date\n      n\n    \n  \n  \n    \n1\n    +00:00\n1322\n  \n  \n  \n\n\n\n\nAlmost all date-time variables are defaulted to UTC +00:00 with the exception of badge variable.\n\n\nBadge situation\nAs its definition says, badge represents a list of badges the user gains by using the app. This variable records the user badges in the following format:\n\n{badge1,badge2,badge3}\nFor example: {B001:2019-07-18T12:15:40-07:00,B004:2019-07-25T07:00:54-07:00,B003:2019-06-18T12:15:40-07:00}\nNot necessarily in order.\n\n\n\n\n Displaying distinct observations in badge variable\n  \n\n\n\nAs we can see, badge variable is recording the UTC offset of the badge gain and this can provide a future solution for the date-time problem if we apply the same principle of date-time recording to the other date-time variables."
  },
  {
    "objectID": "dates_problem.html#obj-2-origin-of-the-problem",
    "href": "dates_problem.html#obj-2-origin-of-the-problem",
    "title": "Date’s problem",
    "section": "Obj 2: Origin of the problem",
    "text": "Obj 2: Origin of the problem\nAs in the duplicate’s problem, part of the problem could be in the extraction of the data by BecharaReport API. Although, for example the atypic values problem also appear in the SQLPad database.\nFurther explanation about the problem could be found in the way SQL’s timestamp & timestampz are being used to store the date-time in AmDTx database. More documentation about this variables could be found in Cockroach Labs, MySQL"
  },
  {
    "objectID": "duplicate_problem.html#problem",
    "href": "duplicate_problem.html#problem",
    "title": "Duplicate’s problem",
    "section": "Problem",
    "text": "Problem\n\nThere are duplicates in the CSV data exported from BecharaReport API."
  },
  {
    "objectID": "duplicate_problem.html#objectives",
    "href": "duplicate_problem.html#objectives",
    "title": "Duplicate’s problem",
    "section": "Objectives",
    "text": "Objectives\n\nDescribe the problem.\nExplain the origin of the problem.\n\nFor the purpose of this report, we are going to use the data from BecharaReport API gathered in 2022-12-24. This data has 552393 observations and 80 variables, and can be found in the following Dropbox path:\nMobio Interactive Dropbox/Research/RWD/Shared R Scripts/Input csv/BecharaReportFull-2022-12-24T06_01_37.csv."
  },
  {
    "objectID": "duplicate_problem.html#obj-1-describing-the-problem",
    "href": "duplicate_problem.html#obj-1-describing-the-problem",
    "title": "Duplicate’s problem",
    "section": "Obj 1: Describing the problem",
    "text": "Obj 1: Describing the problem\nThe current approach to know how many AmDTx unique accounts created in the data is using the following code:\n\n\n\n\n  \n  Unique users with account creation type\n  \n  \n    \n      n\n    \n  \n  \n    732\n  \n  \n  \n\n\n\n\nAt 2022-12-24, we have 732 AmDTx unique accounts created using “account_creation” type. This type of observation is not present in every user, that is why there could be more users present in data.\nThis doesn’t solve duplicates problem, we are just telling R to count the distinct observations in the variable user_uuid filtering only the “account_creation” type.\nIf we want the make calculations about the user metrics, we need the unique observations in the data. For the purpose of this report we are going to select a random user and analyze its duplicates rows:\nUser: 19092f19-792f-42bc-b229-2444b52be4df\n\n\n\nThis user has 449 observations in data. At a glance we can see that this user actually has 16 unique observations. We can use the function distinct() to drop all the duplicates of an observation and only maintain the original one.\n\n\n\n All observation of sample user\n  \n\n\n\n\n\n\nIn this case, now we have 46 observations, which is less but is not 16 observations that is what we want.\nLet’s focus our attention in the session_uuid of the 46 observations. We can see that session_uuid = 292d1290-51a2-4cf2-89e3-7d26628a19a5 repeats 3 times.\n\n\n\n All duplicates of a same observation of sample user\n  \n\n\n\nWe can see that even if this are the same session_uuid, the same observation, there are incongruencies with the following variables:\n\nUpper-lower case problem:\n\nstandalone : has values formatted true/false and also TRUE/FALSE.\n\n\n\n\n\n Upper-lower case problem\n  \n\n\n\n\nRounding problem:\n\no2level_pre, hrv_low_freq_sum_pre, hrv_high_freq_sum_pre, hrv_low_freq_sum_post, hrv_high_freq_sum_post : the same observation could be rounded to the 6 decimal or sometimes more. Is probable that all numeric variables could have this problem.\nreported_stress_pre, reported_stress_post, mood_quality_pre, mood_quality_post : the same observation sometimes has one decimal.\n\n\n\n\n\n Rounding problem\n  \n\n\n\n\nComputing problem:\n\ncomputed_stress_pre, computed_stress_post : this variable has a major issue, because in some cases it reflects the accurate value (e.g 0.4224225) and in other cases its -1 (which is the default when de API finds missing values in this variable). This inconsistency could be a problem in the storage of the data when calling the API.\n\n\n\n\n\n Computing problem\n  \n\n\n\n\nUpdate problem:\n\nbadge : this is a different type of problem. Badge variable collects the information about the badges the user is rewarded. This field keeps updating through the duplicate observation.\n\n\n\n\n\n Update problem\n  \n\n\n\nThe update problem gives us some insight about the general problem in the database. We can see that the problem with the database is not a duplicate problem is a record situation.\n\nRecord situation\nUnderstanding the database as a record data can help us to solve the majority of the problems in the database.\nA solution for the record situation involves the following indications:\n\nRather than keep one of the duplicates randomnly, we can keep the latest observation of the recorded data.\n\nTo know the latest observation in the data, we need a unique id for each observation.\nThis approach can solve the upper-lower case problem, rounding problem, and update problem.\n\nAlthough only applying the solution of the latest observation doesn’t solve the computing problem. It’s necessary to ensure that the preserved observation has the correct computed_stress_pre, computed_stress_post and not only -1 when is not the case."
  },
  {
    "objectID": "duplicate_problem.html#obj-2-origin-of-the-problem",
    "href": "duplicate_problem.html#obj-2-origin-of-the-problem",
    "title": "Duplicate’s problem",
    "section": "Obj 2: Origin of the problem",
    "text": "Obj 2: Origin of the problem\nA hypothesis of the origin of the problem, knowing that is a record situation,\nIn collaboration with Backend team, we determined the origin of the problem was in the API."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mobio report",
    "section": "",
    "text": "Repository of Mobio report."
  },
  {
    "objectID": "note.html",
    "href": "note.html",
    "title": "Mobio Report",
    "section": "",
    "text": "In this case, now we have 46 observations, which is less but is not 16 observations that is what we want.\nLet’s focus our attention in the session_uuid of the 46 observations. We can see that session_uuid = 292d1290-51a2-4cf2-89e3-7d26628a19a5 repeats 3 times.\nWe can see that even if this are the same session_uuid, the same observation, there are incongruencies with the following variables:\nThe update problem gives us some insight about the general problem in the database. We can see that the problem with the database is not a duplicate problem is a record situation."
  },
  {
    "objectID": "note.html#obj-2-origin-of-the-problem",
    "href": "note.html#obj-2-origin-of-the-problem",
    "title": "Mobio Report",
    "section": "Obj 2: Origin of the problem",
    "text": "Obj 2: Origin of the problem\nA hypothesis of the origin of the problem, knowing that is a record situation,\nIn collaboration with Backend team, we determined the origin of the problem was in the API."
  }
]